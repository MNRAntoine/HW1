{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e7e34f73-a3b1-48e5-a2af-ad10a1f7f3ac",
   "metadata": {},
   "source": [
    "# Homework 1 Antoine"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1defea8a-99c0-452f-a6fc-ba7ccdbe5e32",
   "metadata": {},
   "source": [
    "Objective: Use an LSTM to differentiate between human-written and AI-written texts"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f91bf73-d763-46ab-9f12-2935ec849d00",
   "metadata": {},
   "source": [
    "We will first implement 3 different LSTMs. A basic one, a bidirectional one and one accompanied by a CNN. Once we have found the best of the 3 we will focus on improving these hyperparameters to optimize it. \n",
    "(We assume that if a model is worse than another then its optimized version will be worse than the optimized version of the other. This is a strong assumption but it will allow us to avoid varying everything in order to find the best one)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36bcf229-aef6-49fb-b865-645ad23a820c",
   "metadata": {},
   "source": [
    "To initialize the program, we call all the necessary libraries and data. We check that the data is correctly imported."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "47fbacdd-95c1-49c5-8c11-2e604232f2ba",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>text</th>\n",
       "      <th>generated</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Cars. Cars have been around since they became ...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Transportation is a large necessity in most co...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>\"America's love affair with it's vehicles seem...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>How often do you ride in a car? Do you drive a...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Cars are a wonderful thing. They are perhaps o...</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                text  generated\n",
       "0  Cars. Cars have been around since they became ...        0.0\n",
       "1  Transportation is a large necessity in most co...        0.0\n",
       "2  \"America's love affair with it's vehicles seem...        0.0\n",
       "3  How often do you ride in a car? Do you drive a...        0.0\n",
       "4  Cars are a wonderful thing. They are perhaps o...        0.0"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from tensorflow.keras.preprocessing.text import Tokenizer\n",
    "from tensorflow.keras.preprocessing.sequence import pad_sequences\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Embedding, LSTM, Dense, SpatialDropout1D\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "seed = 111\n",
    "\n",
    "data = pd.read_csv('AI_human1.csv')\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88f74f7-0771-4b85-b30c-36e674865613",
   "metadata": {},
   "source": [
    "We divide the dataset by 10 to save processing time. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c1dc2309-fadf-4413-8ddd-3b2febd6b70b",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.sample(frac=0.1, random_state=seed) \n",
    "data.head()\n",
    "label_encoder = LabelEncoder()\n",
    "data['generated'] = label_encoder.fit_transform(data['generated'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47ed9163-b7a2-4198-83d3-b5f12ec0361a",
   "metadata": {},
   "source": [
    "We randomly print 5 texts to see if they need to be cleaned or not. At first sight, it is impossible to differentiate between AI-generated texts and human texts. Therefore, there is no processing to be done on the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0e5257de-5f69-4ab6-afa6-36958756f16c",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Exemples de textes du dataset :\n",
      "Texte 6367: Venus is one of the brightest points of light in the night sky and the closest in distance as well. However, the Venus has proved a very challenging place to explore or to examine more closely. In this exploring process, it will have a variety of stumbling blocks to make scientists stop to explore it. But actually, striving to meet the challenge presented by Venus has value, not only because of the insight to be gained on the planet itself, but also because human curiosity will likely lead us into many equally intimidating endeavors. So that's why people studying Venus is a worthy pursuit despite the dangers it presents.\n",
      "\n",
      "Here are some evidences regarding why the people still to explore it. For instance: Our travels on Earth and beyond should not be limited by dangers and doubts but should be expanded to meet the very edges of imagination and innovation (Paragraph 8). According to this evidence of the article, I can see innovation can help people discover more meaningful things and make country's development gradually more flourishing than before. \" NASA is working on other approaches to studying Venus.\" \" The thought of computers existing in those days may sound shocking, but these devices make calculations by using gears and levers and do not require electronics at all.\" (Paragraph 7) From those evidences, I know they've met important problems to solve when they were exploring Venus, but they still work on this project and try to use different ways or technology to solve those difficulties in not good conditions.\n",
      "\n",
      "All above, despite the danger presents, we can use imagination or innovation methods to create and explore new works of our life, because that not only is able to help us improve our technology skills and the Venus is a valuable science achievement but also it despairs to explore the Venus. So that's why the author suggests that studying Venus is a worthy pursuit despite the dangers it presents.   (Label: 0)\n",
      "\n",
      "Texte 24263: I wholeheartedly agree with the statement that the best way to travel is in a group led by a tour guide. There are so many benefits to traveling with a tour guide. First and foremost, a tour guide is a knowledgeable expert on the area you are visiting. They have extensive knowledge of the history, culture, and attractions of the destination. This means that you will be able to enjoy your trip to the fullest and learn as much as Possible.\n",
      "\n",
      "Another great benefit of traveling with a tour guide is that they can Provide you with insider thus and advice on what to see and do. This can save you a lot of time and money. Finally, a tour guide can be a great source of support. If you are feeling overwhelmed or anxious about your trip, a tour guide can be a calming Presence and offer advice on how to deal with any challenges.\n",
      "\n",
      "Overall, I believe that traveling with a tour guide is the best way to experience a destination. There are so many benefits to having a knowledgeable guide at your side, and I believe that everyone should experience at least one trip with a tour guide.\n",
      "\n",
      " (Label: 1)\n",
      "\n",
      "Texte 25121: AH an eighth grade Student, I have had the opportunity to attend both traditional School and online clashed. While both have their advantage, I Strongly believe that attending School in person IH more beneficial. In this essay, I will argue why attending School IH more beneficial than attending online clashed and provide example of the way Hit IH more beneficial.\n",
      "\n",
      "Firstly, attending School in person allow for more opportunities for Social interaction. School provide a platform for Students to interact with their peer and form meaningful relationship. This interaction help Students develop important Social Hill Such ah communication, teamwork, and empathy. For example, when working on group project, Students learn to collaborate with other and compromise to achieve a common goal. Additionally, attending School in person allow for the opportunity to build friendship and participate in extracurricular activities. There experience help Students develop a Hence of community and belonging.\n",
      "\n",
      "Secondly, attending School in person allow for more opportunities for hand Hon learning. Many Subject require practical experience and experimentation, which can only be gained through unperson instruction. For example, in Science clash, Students can conduct experiment and analyze data in a lab Getting. In art clash, Students can work on their project under the guidance of a teacher. There hand Hon experience help Students develop a deeper understanding of the Subject matter and gain valuable Hill that will benefit them in the future.\n",
      "\n",
      "Lastly, attending School in person provide a Structured learning environment. School provide a Schedule and routine that help Students Stay organized and focused. This Structure help Students develop important time management Hill that will benefit them in the future. Additionally, attending School in person provide a Hence of accountability. Student Hare expected to attend clash and complete alignment on time, which help them develop responsibility and Self-discipline.\n",
      "\n",
      "In conclusion, attending School in person haH numerous benefit that cannot be replicated by online clashed. The opportunities for Social interaction, hand Hon learning, and a Structured learning environment all contribute to a more well rounded and Successful educational experience. While online clashed may have their advantage, I Strongly believe that attending School in person IH the best option for Students. (Label: 1)\n",
      "\n",
      "Texte 40600: I believe that arts education is essential for a well-rounded education. There are several reasons why I hold this position.\n",
      "\n",
      "Firstly, arts education helps students develop their creativity and imagination. When students participate in activities such as painting, drawing or playing an instrument, they are encouraged to think outside the box and come up with unique ideas. This skill is not only important in the arts but also in other areas of life, such as problem-solving and critical thinking.\n",
      "\n",
      "Secondly, arts education can improve a student's academic performance. Studies have shown that students who participate in arts programs tend to have higher grades and test scores than those who do not. For example, a study conducted by the National Endowment for the Arts found that students who took part in arts programs had better attendance, fewer disciplinary problems, and higher graduation rates.\n",
      "\n",
      "Finally, arts education provides students with an outlet for self-expression. Many students struggle to express themselves verbally, but they may find it easier to communicate their thoughts and feelings through art. This can be particularly beneficial for students who are shy or have difficulty making friends.\n",
      "\n",
      "In conclusion, I believe that arts education should be an essential part of every student's education. It helps develop creativity and imagination, improves academic performance, and provides an outlet for self-expression. While some may argue that arts education should be optional, I believe that it is too important to be left up to chance. (Label: 1)\n",
      "\n",
      "Texte 17506: As the years go by there had seemed to be more and more solution in the world. Most of that solution had been seen to be produced by cars, which some people wouldn't know how to live without. However, studies have shown that some cities around the world have actually decreased the usage of cars. A city that has virtually no cars would be Vauban, Germany, and other cities such as Paris, France, Bogotá, Colombia, and even some in the United States have joined in the decreasing of car use wagon. In turn of not using cars as much the solution has gone down in those cities.\n",
      "\n",
      "To begin with, Vauban, Germany, in this German city\" Street parking, driveways and home garages are generally forbidden in this experimental new district on the outskirts of Freiburg, near the French and Swiss borders. Vauban's streets are completely 'carefree' except the main thoroughfare, where the tram to downtown Freiburg runs, and a few streets on one edge of the community. Car ownership is allowed, but there are only two places to park large garages at the edge of the development, where a car owner buys a space, for $40,000, along with a home.\"(P2, In German Suburb, Life Goes On Without Cars, Elisabeth Rosenthal) And in Paris,\" After days of near record pollution, Paris enforced a partial driving ban to clear the air of the global city. On Monday motorists with even numbered license plates were ordered to leave their cars at home or suffer a 22euro fine ($31). The same would apply to odd numbered plates the following day. Almost 4,000 drivers were fined, according to Reuters ... [Twenty seven] people had their cars impounded for their reaction to the fine.\"(P1013, Paris bans driving due to smog, Robert suffer) That might seem a little harsh to some people but in turn\" Congestion was down 60 percent in the capital of France, after five days of intensifying smog ...(P14, Paris bans driving due to smog, Robert suffer)\n",
      "\n",
      "Then there's Bogotá, Colombia, where,\" In a program that's set to spread to other countries, millions of Colombians hiked, biked, skated or took buses to work during a carefree day yesterday, leaving the streets of this capital city eerily devoid of traffic jams. It was the third straight year cars have been banned with only buses and taxis permitted for the fay Without Cars in this capital city of 7 million. The goal is to promote alternative transportation and reduce smog. Violates faced $25 fines. The turnout was large, despite gray clouds that dumped occasional rain showers on Bogotá.\" (P2022, Carefree day is spinning into a big hit in Bogotá, Andrew Silky) This is a pretty good sign from Colombia, showing that it's being consistent with its program and not stopping despite the rain. Also, now even the United States is using fewer cars,\" America's love affair with its vehicles seems to be cooling. When adjusted for population growth, the number of miles driven in the United States peaked in 2005 and dropped steadily thereafter, according to an analysis by four Short of Advisor Perspectives, an investment research company. As of April 2013, the number of miles driven per person was nearly 9 percent below the peak and equal to where the country was in January 1995.\" (P 32, The End of Car Culture, Elisabeth Rosenthal)\n",
      "\n",
      "To conclude, it's great that more and more cities are pitching in to reduce solution due to cars. There are great advantages coming from the reduction of car usage, the best being less solution and smog. If more cities join in and the current cities keep doing what they are doing there could possibly be an even more dramatic decrease in the solution produced today.   (Label: 0)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Exemples de textes du dataset :\")\n",
    "for i in np.random.choice(len(data), 5, replace=False):\n",
    "    print(f\"Texte {i+1}: {data['text'].iloc[i]} (Label: {data['generated'].iloc[i]})\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2baa04a9-444c-44b1-9f95-96e15a6aae85",
   "metadata": {},
   "source": [
    "We slit the dataset in 3 groups train, test and validation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6e043c2d-b7cd-4de9-bdb5-f4ec69b62a15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: 38979, Validation size: 4872, Test size: 4873\n",
      "Train labels distribution:\n",
      " generated\n",
      "0    24334\n",
      "1    14645\n",
      "Name: count, dtype: int64\n",
      "Validation labels distribution:\n",
      " generated\n",
      "0    3039\n",
      "1    1833\n",
      "Name: count, dtype: int64\n",
      "Test labels distribution:\n",
      " generated\n",
      "0    3053\n",
      "1    1820\n",
      "Name: count, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "# We divide the dataset\n",
    "train_data, temp_data = train_test_split(data, test_size=0.2, random_state=seed)\n",
    "val_data, test_data = train_test_split(temp_data, test_size=0.5, random_state=seed)\n",
    "\n",
    "\n",
    "print(f\"Train size: {train_data.shape[0]}, Validation size: {val_data.shape[0]}, Test size: {test_data.shape[0]}\")\n",
    "print(\"Train labels distribution:\\n\", train_data['generated'].value_counts())\n",
    "print(\"Validation labels distribution:\\n\", val_data['generated'].value_counts())\n",
    "print(\"Test labels distribution:\\n\", test_data['generated'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a826895f-05ed-4265-aa74-0a0ee07e502c",
   "metadata": {},
   "source": [
    "Tockenisation: (We tockenized in the simplest way with Keras. There are many, some of which are more useful depending on the model. For example, the LSTM + CNN model works better with Bert tokenization. For a complete test, it would therefore be necessary to also evaluate the models with their optimal tokenization.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "416a2032-0ad3-40c8-b184-a1bb0d374f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenisation\n",
    "max_words = 5000\n",
    "max_len = 150\n",
    "\n",
    "tokenizer = Tokenizer(num_words=max_words)\n",
    "tokenizer.fit_on_texts(train_data['text'])\n",
    "\n",
    "X_train = tokenizer.texts_to_sequences(train_data['text'])\n",
    "X_val = tokenizer.texts_to_sequences(val_data['text'])\n",
    "X_test = tokenizer.texts_to_sequences(test_data['text'])\n",
    "\n",
    "# Padding\n",
    "X_train = pad_sequences(X_train, maxlen=max_len)\n",
    "X_val = pad_sequences(X_val, maxlen=max_len)\n",
    "X_test = pad_sequences(X_test, maxlen=max_len)\n",
    "\n",
    "y_train = train_data['generated']\n",
    "y_val = val_data['generated']\n",
    "y_test = test_data['generated']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b6820af-2ffa-468f-afce-dfed57ebcb13",
   "metadata": {},
   "source": [
    "Our first simple LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "035587e3-3108-4b06-83c9-c1e566929efc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\munie\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\keras\\src\\layers\\core\\embedding.py:90: UserWarning: Argument `input_length` is deprecated. Just remove it.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m154s\u001b[0m 235ms/step - accuracy: 0.8726 - loss: 0.2899 - val_accuracy: 0.9731 - val_loss: 0.0889\n",
      "Epoch 2/5\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m193s\u001b[0m 221ms/step - accuracy: 0.8981 - loss: 0.2997 - val_accuracy: 0.9019 - val_loss: 0.2573\n",
      "Epoch 3/5\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 221ms/step - accuracy: 0.9655 - loss: 0.1133 - val_accuracy: 0.9799 - val_loss: 0.0726\n",
      "Epoch 4/5\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m135s\u001b[0m 222ms/step - accuracy: 0.9807 - loss: 0.0675 - val_accuracy: 0.9809 - val_loss: 0.0661\n",
      "Epoch 5/5\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m130s\u001b[0m 214ms/step - accuracy: 0.9879 - loss: 0.0431 - val_accuracy: 0.9840 - val_loss: 0.0542\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 38ms/step - accuracy: 0.9866 - loss: 0.0481\n",
      "Test Accuracy: 0.9858\n"
     ]
    }
   ],
   "source": [
    "# bulding a simple LSTM\n",
    "model = Sequential()\n",
    "model.add(Embedding(max_words, 100, input_length=max_len))\n",
    "model.add(SpatialDropout1D(0.2))\n",
    "model.add(LSTM(100, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
    "\n",
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# training\n",
    "history = model.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping],verbose=1)\n",
    "\n",
    "# Evaluation\n",
    "loss, accuracy = model.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy: {accuracy:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0d4f2500-8a3a-4728-ba94-fb9040781e31",
   "metadata": {},
   "source": [
    "The results are too good to be realistic. An LSTM has a success rate of between 75 and 85%. I've tried everything to find the source of the problem, but I still can't find it. This ruins the exercise because if the simplest model is already perfect, then the rest is useless"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e8b0090-e5e8-4ef8-9bbf-fadce73802e3",
   "metadata": {},
   "source": [
    "Création of Bidirectional LSTM:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "2166f6df-99d4-46cd-a720-e2224a3b19b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Bidirectional\n",
    "\n",
    "# Bidirectional LSTM\n",
    "model_bidirectional = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "model_bidirectional.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cb78a7dd-7548-496f-a777-ce85f6edc966",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m428s\u001b[0m 3s/step - accuracy: 0.8122 - loss: 0.3833 - val_accuracy: 0.9791 - val_loss: 0.0671\n",
      "Epoch 2/5\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m445s\u001b[0m 3s/step - accuracy: 0.9813 - loss: 0.0632 - val_accuracy: 0.9846 - val_loss: 0.0506\n",
      "Epoch 3/5\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m458s\u001b[0m 3s/step - accuracy: 0.9877 - loss: 0.0435 - val_accuracy: 0.9819 - val_loss: 0.0585\n",
      "Epoch 4/5\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m460s\u001b[0m 3s/step - accuracy: 0.9896 - loss: 0.0374 - val_accuracy: 0.9838 - val_loss: 0.0506\n",
      "Epoch 5/5\n",
      "\u001b[1m148/148\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m478s\u001b[0m 3s/step - accuracy: 0.9896 - loss: 0.0360 - val_accuracy: 0.9862 - val_loss: 0.0420\n",
      "\u001b[1m153/153\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m17s\u001b[0m 111ms/step - accuracy: 0.9903 - loss: 0.0335\n",
      "Test Accuracy (Bidirectional LSTM): 0.9885\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# Early stopping (to stop before overfitting)\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# training\n",
    "history_bidirectional = model_bidirectional.fit(X_train, y_train, epochs=5, batch_size=264, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "loss_bidirectional, accuracy_bidirectional = model_bidirectional.evaluate(X_test, y_test)\n",
    "print(f'Test Accuracy (Bidirectional LSTM): {accuracy_bidirectional:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbcb9d5f-17fa-4e11-9786-37f96da4908b",
   "metadata": {},
   "source": [
    "The results are also too good. This shows that the problem is not the model but the data. (I added lines at the beginning of the code to check certain values to find the problem) (as you can still see the bad results you understand that I have not found anything)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "123073c1-ebb2-4ccb-9ce2-b7057c867e20",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.layers import Conv1D, MaxPooling1D\n",
    "\n",
    "model_lstm_cnn = Sequential([\n",
    "    Embedding(input_dim=max_words, output_dim=100),\n",
    "    SpatialDropout1D(0.2),\n",
    "\n",
    "    # Convolution Conv1D\n",
    "    Conv1D(filters=64, kernel_size=5, activation='relu'),\n",
    "    MaxPooling1D(pool_size=4),\n",
    "\n",
    "    Bidirectional(LSTM(100, dropout=0.2, recurrent_dropout=0.2)),\n",
    "\n",
    "    Dense(1, activation='sigmoid')\n",
    "])\n",
    "\n",
    "model_lstm_cnn.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "df51b5bd-65a4-46ae-a767-48f1a537328e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/5\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m81s\u001b[0m 107ms/step - accuracy: 0.8899 - loss: 0.2301 - val_accuracy: 0.9807 - val_loss: 0.0580\n",
      "Epoch 2/5\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 105ms/step - accuracy: 0.9888 - loss: 0.0360 - val_accuracy: 0.9881 - val_loss: 0.0432\n",
      "Epoch 3/5\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m66s\u001b[0m 109ms/step - accuracy: 0.9932 - loss: 0.0219 - val_accuracy: 0.9850 - val_loss: 0.0554\n",
      "Epoch 4/5\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m65s\u001b[0m 106ms/step - accuracy: 0.9956 - loss: 0.0167 - val_accuracy: 0.9776 - val_loss: 0.0709\n",
      "Epoch 5/5\n",
      "\u001b[1m610/610\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m64s\u001b[0m 105ms/step - accuracy: 0.9960 - loss: 0.0129 - val_accuracy: 0.9881 - val_loss: 0.0480\n",
      "Test Accuracy (LSTM-CNN): 0.9887\n"
     ]
    }
   ],
   "source": [
    "# Early stopping\n",
    "early_stopping = EarlyStopping(monitor='val_loss', patience=3, restore_best_weights=True)\n",
    "\n",
    "# training the model\n",
    "history_lstm_cnn = model_lstm_cnn.fit(X_train, y_train, epochs=5, batch_size=64, validation_data=(X_val, y_val), callbacks=[early_stopping], verbose=1)\n",
    "\n",
    "loss_lstm_cnn, accuracy_lstm_cnn = model_lstm_cnn.evaluate(X_test, y_test, verbose=0)\n",
    "print(f'Test Accuracy (LSTM-CNN): {accuracy_lstm_cnn:.4f}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa35d7de-af8f-4048-9d43-8097eee01006",
   "metadata": {},
   "source": [
    "once again the model is close to perfection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6dacd7e6-b474-4be2-88a2-d808335cf73a",
   "metadata": {},
   "source": [
    "# Conclusion:\n",
    "The conclusion is not going to be very interesting because unfortunately I have not solved my problem on my data. Our 3 models are excellent because the data are problematic. We can therefore deduce nothing from it even if we easily imagine that the bidirectional model and CNN are normally better than the classic model."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8c577e7-9d20-4b08-b4be-4bdf4cb2f959",
   "metadata": {},
   "source": [
    "If the data had no problems we would have varied the embedding, dropout rate, batch_size and other parameters to find the optimal version (for our dataset)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a84446f-803f-4cc0-bdba-a0dcb79fc837",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
